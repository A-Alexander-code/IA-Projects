{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4972,"status":"ok","timestamp":1719610375960,"user":{"displayName":"Astrian Vorgia","userId":"17702708023283906308"},"user_tz":300},"id":"rQfSy1kWz6Nj"},"outputs":[],"source":["# Libraries\n","import tensorflow as tf\n","import pandas as pd\n","from my_data_generator import DataGenerator\n","from convolutional_autoencoder import ConvAutoencoder\n","from utils import save_reconstructed_images, create_environment, create_json\n","from tensorflow.keras.models import load_model\n","import os\n","import numpy as np\n","import cv2"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":317,"status":"ok","timestamp":1719610401015,"user":{"displayName":"Astrian Vorgia","userId":"17702708023283906308"},"user_tz":300},"id":"g-M-MW5y0qBh"},"outputs":[],"source":["#Hyper-parameters\n","\n","input_dim = (128, 128, 1)\n","encoder_conv_filters = [32, 64, 64, 64]\n","encoder_conv_kernel_size = [3, 3, 3, 3]\n","encoder_conv_strides = [2, 2, 2, 2]\n","decoder_conv_t_filters = [64, 64, 32, 1]\n","decoder_conv_t_kernel_size = [3, 3, 3, 3]\n","decoder_conv_t_strides = [2, 2, 2, 2]\n","sess = tf.function()\n","z_dim = 200\n","learning_rate = 0.0005\n","batch_size = 8\n","epochs = 50\n","r_loss_factor = 0.4\n","is_training = True"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":411,"status":"ok","timestamp":1719610404008,"user":{"displayName":"Astrian Vorgia","userId":"17702708023283906308"},"user_tz":300},"id":"VENem6Tk4d04"},"outputs":[],"source":["base_folder = \"/content/drive/MyDrive/convolutional_autoencoder/\"\n","#I/O paths\n","run_folders = {\"tsv_path\": base_folder + \"data/partition.csv\",\n","               \"data_path\": base_folder + \"data/images/\",\n","               \"model_path\": base_folder + \"data/Models/\",\n","               \"results_path\": base_folder + \"data/Results/\",\n","               \"log_filename\": base_folder + \"data/Results/log/CAE.log\"\n","               }"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":366,"status":"ok","timestamp":1719610406505,"user":{"displayName":"Astrian Vorgia","userId":"17702708023283906308"},"user_tz":300},"id":"j2nDQ_Dt5Wm1"},"outputs":[],"source":["# Creating the directory structure\n","create_environment(run_folders)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":581,"status":"ok","timestamp":1719610410505,"user":{"displayName":"Astrian Vorgia","userId":"17702708023283906308"},"user_tz":300},"id":"OYNq9GBU3McT"},"outputs":[],"source":["hyperparameters = {\"input_dim\": input_dim,\n","                   \"encoder_conv_filters\": encoder_conv_filters,\n","                   \"encoder_conv_kernel_size\":encoder_conv_kernel_size,\n","                   \"encoder_conv_strides\":encoder_conv_strides,\n","                   \"decoder_conv_t_filters\":decoder_conv_t_filters,\n","                   \"decoder_conv_t_kernel_size\":decoder_conv_t_kernel_size,\n","                   \"decoder_conv_t_strides\":decoder_conv_t_strides,\n","                   \"z_dim\":z_dim,\n","                   \"learning_rate\":learning_rate,\n","                   \"batch_size\":batch_size,\n","                   \"epochs\":epochs,\n","                   \"r_loss_factor\":r_loss_factor,\n","                   \"opt\":\"Adam\",\n","                   \"loss_function\":\"mse\",\n","                   \"data_path\": run_folders[\"data_path\"]\n","                   }\n","create_json(hyperparameters, run_folders)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1058362,"status":"ok","timestamp":1719611471466,"user":{"displayName":"Astrian Vorgia","userId":"17702708023283906308"},"user_tz":300},"id":"YsXtEphD8S0i","outputId":"247ba88c-1b1f-4655-8c2e-245b7f3f09c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," encoder_input (InputLayer)  [(None, 128, 128, 1)]     0         \n","                                                                 \n"," encoder_conv0 (Conv2D)      (None, 64, 64, 32)        320       \n","                                                                 \n"," batch_normalization (Batch  (None, 64, 64, 32)        128       \n"," Normalization)                                                  \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 64, 64, 32)        0         \n","                                                                 \n"," encoder_conv1 (Conv2D)      (None, 32, 32, 64)        18496     \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 32, 32, 64)        256       \n"," chNormalization)                                                \n","                                                                 \n"," leaky_re_lu_1 (LeakyReLU)   (None, 32, 32, 64)        0         \n","                                                                 \n"," encoder_conv2 (Conv2D)      (None, 16, 16, 64)        36928     \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n"," chNormalization)                                                \n","                                                                 \n"," leaky_re_lu_2 (LeakyReLU)   (None, 16, 16, 64)        0         \n","                                                                 \n"," encoder_conv3 (Conv2D)      (None, 8, 8, 64)          36928     \n","                                                                 \n"," batch_normalization_3 (Bat  (None, 8, 8, 64)          256       \n"," chNormalization)                                                \n","                                                                 \n"," leaky_re_lu_3 (LeakyReLU)   (None, 8, 8, 64)          0         \n","                                                                 \n"," flatten (Flatten)           (None, 4096)              0         \n","                                                                 \n"," encoder_output (Dense)      (None, 200)               819400    \n","                                                                 \n"," model_1 (Functional)        (None, 128, 128, 1)       915905    \n","                                                                 \n","=================================================================\n","Total params: 1828873 (6.98 MB)\n","Trainable params: 1828425 (6.97 MB)\n","Non-trainable params: 448 (1.75 KB)\n","_________________________________________________________________\n","None\n","[INFO]: Training\n","Epoch 1/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0429\n","Epoch 1: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 260s 6s/step - loss: 0.0429 - val_loss: 0.0467 - lr: 5.0000e-04\n","Epoch 2/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0169\n","Epoch 2: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 317ms/step - loss: 0.0169 - val_loss: 0.0448 - lr: 5.0000e-04\n","Epoch 3/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0136\n","Epoch 3: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 315ms/step - loss: 0.0136 - val_loss: 0.0422 - lr: 5.0000e-04\n","Epoch 4/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0111\n","Epoch 4: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 314ms/step - loss: 0.0111 - val_loss: 0.0384 - lr: 5.0000e-04\n","Epoch 5/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0096\n","Epoch 5: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 16s 354ms/step - loss: 0.0096 - val_loss: 0.0330 - lr: 5.0000e-04\n","Epoch 6/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0088\n","Epoch 6: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 321ms/step - loss: 0.0088 - val_loss: 0.0299 - lr: 5.0000e-04\n","Epoch 7/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0082\n","Epoch 7: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 327ms/step - loss: 0.0082 - val_loss: 0.0254 - lr: 5.0000e-04\n","Epoch 8/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0073\n","Epoch 8: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 321ms/step - loss: 0.0073 - val_loss: 0.0262 - lr: 5.0000e-04\n","Epoch 9/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0070\n","Epoch 9: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 320ms/step - loss: 0.0070 - val_loss: 0.0162 - lr: 5.0000e-04\n","Epoch 10/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0070\n","Epoch 10: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 329ms/step - loss: 0.0070 - val_loss: 0.0159 - lr: 5.0000e-04\n","Epoch 11/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0067\n","Epoch 11: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 319ms/step - loss: 0.0067 - val_loss: 0.0101 - lr: 5.0000e-04\n","Epoch 12/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0071\n","Epoch 12: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 317ms/step - loss: 0.0071 - val_loss: 0.0091 - lr: 5.0000e-04\n","Epoch 13/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0061\n","Epoch 13: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 17s 389ms/step - loss: 0.0061 - val_loss: 0.0067 - lr: 5.0000e-04\n","Epoch 14/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0060\n","Epoch 14: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 325ms/step - loss: 0.0060 - val_loss: 0.0059 - lr: 5.0000e-04\n","Epoch 15/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0058\n","Epoch 15: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 15s 350ms/step - loss: 0.0058 - val_loss: 0.0062 - lr: 5.0000e-04\n","Epoch 16/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0055\n","Epoch 16: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 323ms/step - loss: 0.0055 - val_loss: 0.0075 - lr: 5.0000e-04\n","Epoch 17/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0058\n","Epoch 17: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 319ms/step - loss: 0.0058 - val_loss: 0.0060 - lr: 5.0000e-04\n","Epoch 18/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0055\n","Epoch 18: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 319ms/step - loss: 0.0055 - val_loss: 0.0060 - lr: 5.0000e-04\n","Epoch 19/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0052\n","Epoch 19: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 326ms/step - loss: 0.0052 - val_loss: 0.0055 - lr: 5.0000e-04\n","Epoch 20/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0054\n","Epoch 20: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 327ms/step - loss: 0.0054 - val_loss: 0.0054 - lr: 5.0000e-04\n","Epoch 21/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0051\n","Epoch 21: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 15s 346ms/step - loss: 0.0051 - val_loss: 0.0055 - lr: 5.0000e-04\n","Epoch 22/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0046\n","Epoch 22: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 320ms/step - loss: 0.0046 - val_loss: 0.0051 - lr: 5.0000e-04\n","Epoch 23/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0046\n","Epoch 23: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 314ms/step - loss: 0.0046 - val_loss: 0.0051 - lr: 5.0000e-04\n","Epoch 24/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0045\n","Epoch 24: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 318ms/step - loss: 0.0045 - val_loss: 0.0050 - lr: 5.0000e-04\n","Epoch 25/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0043\n","Epoch 25: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 314ms/step - loss: 0.0043 - val_loss: 0.0050 - lr: 5.0000e-04\n","Epoch 26/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0043\n","Epoch 26: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 323ms/step - loss: 0.0043 - val_loss: 0.0050 - lr: 5.0000e-04\n","Epoch 27/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0043\n","Epoch 27: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 318ms/step - loss: 0.0043 - val_loss: 0.0051 - lr: 5.0000e-04\n","Epoch 28/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0043\n","Epoch 28: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 317ms/step - loss: 0.0043 - val_loss: 0.0051 - lr: 5.0000e-04\n","Epoch 29/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0040\n","Epoch 29: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 15s 351ms/step - loss: 0.0040 - val_loss: 0.0049 - lr: 5.0000e-04\n","Epoch 30/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0041\n","Epoch 30: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 321ms/step - loss: 0.0041 - val_loss: 0.0064 - lr: 5.0000e-04\n","Epoch 31/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0040\n","Epoch 31: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 325ms/step - loss: 0.0040 - val_loss: 0.0051 - lr: 5.0000e-04\n","Epoch 32/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0043\n","Epoch 32: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 322ms/step - loss: 0.0043 - val_loss: 0.0057 - lr: 5.0000e-04\n","Epoch 33/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0037\n","Epoch 33: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 317ms/step - loss: 0.0037 - val_loss: 0.0050 - lr: 5.0000e-04\n","Epoch 34/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0037\n","Epoch 34: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 319ms/step - loss: 0.0037 - val_loss: 0.0047 - lr: 5.0000e-04\n","Epoch 35/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0036\n","Epoch 35: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 312ms/step - loss: 0.0036 - val_loss: 0.0048 - lr: 5.0000e-04\n","Epoch 36/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0033\n","Epoch 36: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 15s 348ms/step - loss: 0.0033 - val_loss: 0.0045 - lr: 5.0000e-04\n","Epoch 37/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0034\n","Epoch 37: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 15s 351ms/step - loss: 0.0034 - val_loss: 0.0048 - lr: 5.0000e-04\n","Epoch 38/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0036\n","Epoch 38: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 318ms/step - loss: 0.0036 - val_loss: 0.0049 - lr: 5.0000e-04\n","Epoch 39/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0034\n","Epoch 39: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 326ms/step - loss: 0.0034 - val_loss: 0.0048 - lr: 5.0000e-04\n","Epoch 40/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0034\n","Epoch 40: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 322ms/step - loss: 0.0034 - val_loss: 0.0048 - lr: 5.0000e-04\n","Epoch 41/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0032\n","Epoch 41: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 325ms/step - loss: 0.0032 - val_loss: 0.0047 - lr: 5.0000e-04\n","Epoch 42/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0031\n","Epoch 42: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 332ms/step - loss: 0.0031 - val_loss: 0.0047 - lr: 5.0000e-04\n","Epoch 43/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0032\n","Epoch 43: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 15s 345ms/step - loss: 0.0032 - val_loss: 0.0047 - lr: 5.0000e-04\n","Epoch 44/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0031\n","Epoch 44: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 321ms/step - loss: 0.0031 - val_loss: 0.0049 - lr: 5.0000e-04\n","Epoch 45/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0032\n","Epoch 45: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 315ms/step - loss: 0.0032 - val_loss: 0.0048 - lr: 5.0000e-04\n","Epoch 46/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0030\n","Epoch 46: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 315ms/step - loss: 0.0030 - val_loss: 0.0046 - lr: 5.0000e-04\n","Epoch 47/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0030\n","Epoch 47: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 318ms/step - loss: 0.0030 - val_loss: 0.0047 - lr: 5.0000e-04\n","Epoch 48/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0029\n","Epoch 48: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 323ms/step - loss: 0.0029 - val_loss: 0.0047 - lr: 5.0000e-04\n","Epoch 49/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0031\n","Epoch 49: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 14s 323ms/step - loss: 0.0031 - val_loss: 0.0049 - lr: 5.0000e-04\n","Epoch 50/50\n","44/44 [==============================] - ETA: 0s - loss: 0.0029\n","Epoch 50: saving model to /content/drive/MyDrive/convolutional_autoencoder/data/Models/exp_0006/weights/CAE_weights.h5\n","44/44 [==============================] - 15s 339ms/step - loss: 0.0029 - val_loss: 0.0048 - lr: 5.0000e-04\n"]}],"source":["# Training phase\n","if is_training:\n","  # Data loading\n","  df_pneumo_2d = pd.read_csv(run_folders[\"tsv_path\"], sep=\";\")\n","  df_pneumo_2d.columns = ['ImageID', 'Partition', 'Class']\n","  data_filter = df_pneumo_2d['Partition']=='train'\n","  # Training data loader\n","  data_flow_train = DataGenerator(df_pneumo_2d[data_filter],\n","                                  input_dim[1],\n","                                  input_dim[0],\n","                                  input_dim[2],\n","                                  batch_size=batch_size,\n","                                  path_to_img=run_folders[\"data_path\"],\n","                                  shuffle = True)\n","  # VAlidation data loader\n","  data_filter = df_pneumo_2d['Partition']=='val'\n","  data_flow_val = DataGenerator(df_pneumo_2d[data_filter],\n","                                  input_dim[1],\n","                                  input_dim[0],\n","                                  input_dim[2],\n","                                  batch_size=batch_size,\n","                                  path_to_img=run_folders[\"data_path\"],\n","                                  )\n","  # Creating the CAE\n","  my_CAE = ConvAutoencoder(input_dim,\n","                           encoder_conv_filters,\n","                           encoder_conv_kernel_size,\n","                           encoder_conv_strides,\n","                           decoder_conv_t_filters,\n","                           decoder_conv_t_kernel_size,\n","                           decoder_conv_t_strides,\n","                           z_dim)\n","\n","  # Building architecture\n","  my_CAE.build(use_batch_norm=True, use_dropout=False, VCAE=False)\n","  print(my_CAE.model.summary())\n","\n","  # Compiling the CAE\n","  my_CAE.compile(learning_rate=learning_rate, r_loss_factor=r_loss_factor)\n","\n","  # Training the CAE\n","  steps_per_epoch = len(data_flow_train)\n","  H = my_CAE.train(data_flow_train, epochs, steps_per_epoch, data_flow_val, run_folders)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5610,"status":"ok","timestamp":1719611494238,"user":{"displayName":"Astrian Vorgia","userId":"17702708023283906308"},"user_tz":300},"id":"TXnporZz_-2Y","outputId":"cf623075-b811-430a-86bb-64ed3edcc3f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," encoder_input (InputLayer)  [(None, 128, 128, 1)]     0         \n","                                                                 \n"," encoder_conv0 (Conv2D)      (None, 64, 64, 32)        320       \n","                                                                 \n"," batch_normalization (Batch  (None, 64, 64, 32)        128       \n"," Normalization)                                                  \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 64, 64, 32)        0         \n","                                                                 \n"," encoder_conv1 (Conv2D)      (None, 32, 32, 64)        18496     \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 32, 32, 64)        256       \n"," chNormalization)                                                \n","                                                                 \n"," leaky_re_lu_1 (LeakyReLU)   (None, 32, 32, 64)        0         \n","                                                                 \n"," encoder_conv2 (Conv2D)      (None, 16, 16, 64)        36928     \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n"," chNormalization)                                                \n","                                                                 \n"," leaky_re_lu_2 (LeakyReLU)   (None, 16, 16, 64)        0         \n","                                                                 \n"," encoder_conv3 (Conv2D)      (None, 8, 8, 64)          36928     \n","                                                                 \n"," batch_normalization_3 (Bat  (None, 8, 8, 64)          256       \n"," chNormalization)                                                \n","                                                                 \n"," leaky_re_lu_3 (LeakyReLU)   (None, 8, 8, 64)          0         \n","                                                                 \n"," flatten (Flatten)           (None, 4096)              0         \n","                                                                 \n"," encoder_output (Dense)      (None, 200)               819400    \n","                                                                 \n"," model_1 (Functional)        (None, 128, 128, 1)       915905    \n","                                                                 \n","=================================================================\n","Total params: 1828873 (6.98 MB)\n","Trainable params: 1828425 (6.97 MB)\n","Non-trainable params: 448 (1.75 KB)\n","_________________________________________________________________\n","None\n","1/1 [==============================] - 0s 221ms/step\n","(8, 128, 128, 1)\n"]}],"source":["is_training = True\n","# Data loading\n","df_pneumo_2d = pd.read_csv(run_folders[\"tsv_path\"], sep=\";\")\n","df_pneumo_2d.columns = ['ImageID', 'Partition', 'Class']\n","data_filter = df_pneumo_2d['Partition']=='test'\n","# Training data loader\n","data_flow_test = DataGenerator(df_pneumo_2d[data_filter],\n","                                input_dim[1],\n","                                input_dim[0],\n","                                input_dim[2],\n","                                batch_size=batch_size,\n","                                path_to_img=run_folders[\"data_path\"],\n","                                shuffle = False)\n","\n","if not is_training:\n","  my_CAE = ConvAutoencoder.load_model(run_folders)\n","\n","print(my_CAE.model.summary())\n","\n","example_batch = data_flow_test.__getitem__(index=0)\n","example_images = example_batch[0]\n","\n","y_pred = my_CAE.model.predict(example_images)\n","print(y_pred.shape)\n","\n","save_reconstructed_images(example_images, y_pred, run_folders)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1lOhOFcwF6fy"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
